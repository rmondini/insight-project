{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roberto/anaconda3/envs/insight/lib/python3.8/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import csv\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pyLDAvis.sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from gensim import models, corpora\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.matutils import softcossim,cossim\n",
    "import gensim.downloader as api\n",
    "from gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FastText model\n",
    "#fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "STOPWORDS = STOPWORDS + ['good','better','could','would','didnt','money','night','need','like','nothing','one',\n",
    "                         'day','get','time','stay','thing','u','horrible','great','well','ask','never','ever',\n",
    "                         'recommend','place','back','disgusting','terrible','worst','ok','price','pay','paid',\n",
    "                         'even','use','bad','picture','anything','everything','really','think','bit','sure',\n",
    "                         'went','quite','turn','around','dont','feel','work','wasnt','much','complaint','told',\n",
    "                         'hour','line','also','big','small','option','cant','per','cost','extra','said','took',\n",
    "                         'leave','hotel','area','old','new','service','say','want','stayed','worth','time',\n",
    "                         'look','little','way','basic','see','overall','rate']\n",
    "\n",
    "wn_lemmatizer = WordNetLemmatizer()\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    tokenized_text = word_tokenize(text.lower())\n",
    "    cleaned_text = [wn_lemmatizer.lemmatize(p_stemmer.stem(t)) for t in tokenized_text if t not in STOPWORDS]\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences = pd.read_csv('./datasets/df_negative_sentences.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_sentences = pd.read_csv('./datasets/df_positive_sentences.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove empty reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences = df_negative_sentences[~pd.isnull(df_negative_sentences['review_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_sentences = df_positive_sentences[~pd.isnull(df_positive_sentences['review_sentence'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity between topics and reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_topic = 'Noise noisy loud quiet party scream yell voice music thin wall hear talk' + 'Smell smelly smoke odor cigarette stink' + 'Ac heat hot cold warm chilly thermostat cool air conditioning vent ventilation fan adjust heater temperature'\n",
    "staff_topic = 'Staff rude unfriendly friendly polite impolite front desk manager maid reception valet clerk reception housekeep waiter waitress' + 'Check in out checkin checkout communication experience bag early late reservation booking'\n",
    "breakfast_topic = 'Breakfast food egg bacon sausage toast waffle fruit omelette omelet cheese milk pastry coffee tea juice silverware plasticware cup plastic included selection taste'\n",
    "facilities_topic = 'Facility elevator lift work stair floor disability wheelchair pool jacuzzi gym vending machine spa sauna towel renovation bar restaurant lounge pet friendly dinner lunch pit property' + 'WiFi wi fi internet slow connection signal free fast spotty' + 'Park lot car valet street driveway'\n",
    "#parking_topic = 'Park lot car valet street driveway'\n",
    "#smell_topic = 'Smell smelly smoke odor cigarette stink'\n",
    "#ac_heat_topic = 'Ac heat hot cold warm chilly thermostat cool air conditioning vent ventilation fan adjust heater temperature'\n",
    "#wifi_topic = 'WiFi wi fi internet slow connection signal free fast spotty'\n",
    "location_topic = 'Location surrounding far traffic highway walk street road neighborhood sketchy attraction center city town downtown nearby near walk transport subway park view safe dangerous drive'\n",
    "#check_in_out_topic = 'Check in out checkin checkout communication experience bag early late reservation booking'\n",
    "bathroom_topic = 'Bathroom stain shower tub bathtub curtain pressure sink water toiletry toilet mirror shampoo conditioner towel soap ply paper hair hand face wash vent ventilation fan window'\n",
    "room_amenities_topic = 'Room tiny small big large stain curtain shade drape light view window tv balcony service work remote wall fridge refrigerator safe machine coffee tea kettle amenity microwave card door'\n",
    "bed_topic = 'Bed stain sheet linen blanket cover pillow hard soft mattress outlet plug bug bedbug king double queen frame'\n",
    "\n",
    "# smell_topic, wifi_topic, check_in_out_topic, parking_topic, ac_heat_topic\n",
    "topics = [noise_topic,staff_topic,breakfast_topic,facilities_topic,location_topic,bathroom_topic,room_amenities_topic,bed_topic]\n",
    "n_topics = len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For gensim we need to tokenize the data and filter out stopwords\n",
    "tokenized_neg_data = []\n",
    "for text in df_negative_sentences['review_sentence']:\n",
    "    tokenized_neg_data.append(clean_text(text))\n",
    "\n",
    "tokenized_pos_data = []\n",
    "for text in df_positive_sentences['review_sentence']:\n",
    "    tokenized_pos_data.append(clean_text(text))\n",
    "    \n",
    "tokenized_topics = []    \n",
    "for text in topics:\n",
    "    tokenized_topics.append(clean_text(text))\n",
    "    \n",
    "tokenized_neg_data_and_topics = tokenized_neg_data + tokenized_topics\n",
    "tokenized_pos_data_and_topics = tokenized_pos_data + tokenized_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Dictionary - association word to numeric id\n",
    "neg_dictionary = corpora.Dictionary(tokenized_neg_data_and_topics)\n",
    "pos_dictionary = corpora.Dictionary(tokenized_pos_data_and_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the collection of texts to a numerical form\n",
    "corpus_neg_data = [neg_dictionary.doc2bow(text) for text in tokenized_neg_data]\n",
    "corpus_pos_data = [pos_dictionary.doc2bow(text) for text in tokenized_pos_data]\n",
    "corpus_neg_topics = [neg_dictionary.doc2bow(text) for text in tokenized_topics]\n",
    "corpus_pos_topics = [pos_dictionary.doc2bow(text) for text in tokenized_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build similarity matrix with word embeddings from FastText\n",
    "#termsim_index = WordEmbeddingSimilarityIndex(fasttext_model300)\n",
    "#similarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between each sentence and each topic\n",
    "neg_data_topics = []\n",
    "for review_item in corpus_neg_data:\n",
    "    review_item_topics = []\n",
    "    for topic in corpus_neg_topics:\n",
    "        review_item_topics.append(cossim(review_item,topic))\n",
    "        #review_item_topics.append(similarity_matrix.inner_product(review_item,topic,normalized=True))\n",
    "    neg_data_topics.append(review_item_topics)    \n",
    "    \n",
    "pos_data_topics = []\n",
    "for review_item in corpus_pos_data:\n",
    "    review_item_topics = []\n",
    "    for topic in corpus_pos_topics:\n",
    "        review_item_topics.append(cossim(review_item,topic))\n",
    "        #review_item_topics.append(similarity_matrix.inner_product(review_item,topic,normalized=True))\n",
    "    pos_data_topics.append(review_item_topics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data_closest_topic = []\n",
    "for review_item_topic_list in neg_data_topics:\n",
    "    closest_topic_cossim_value = max(review_item_topic_list)\n",
    "    closest_topic = np.argmax(review_item_topic_list)\n",
    "    if closest_topic_cossim_value>0.05:\n",
    "        neg_data_closest_topic.append(closest_topic)\n",
    "    else:\n",
    "        neg_data_closest_topic.append(-1)\n",
    "        \n",
    "pos_data_closest_topic = []\n",
    "for review_item_topic_list in pos_data_topics:\n",
    "    closest_topic_cossim_value = max(review_item_topic_list)\n",
    "    closest_topic = np.argmax(review_item_topic_list)\n",
    "    if closest_topic_cossim_value>0.05:\n",
    "        pos_data_closest_topic.append(closest_topic)\n",
    "    else:\n",
    "        pos_data_closest_topic.append(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign topic with highest cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences['review_topic'] = neg_data_closest_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_sentences['review_topic'] = pos_data_closest_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    69979\n",
       " 6    55249\n",
       " 1    20479\n",
       " 2    18823\n",
       " 5    18801\n",
       " 7    16571\n",
       " 3    15278\n",
       " 0    11879\n",
       " 4    11129\n",
       "Name: review_topic, dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_negative_sentences['review_topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic = df_negative_sentences.groupby(['hotel_url','review_topic']).size().reset_index()\n",
    "df_negative_sentences_by_topic.rename({0:'review_topic_count'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_sentences_by_topic = df_positive_sentences.groupby(['hotel_url','review_topic']).size().reset_index()\n",
    "df_positive_sentences_by_topic.rename({0:'review_topic_count'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt = df_negative_sentences_by_topic.pivot_table(values='review_topic_count',index='hotel_url',columns='review_topic').reset_index()\n",
    "df_negative_sentences_by_topic_pt.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_sentences_by_topic_pt = df_positive_sentences_by_topic.pivot_table(values='review_topic_count',index='hotel_url',columns='review_topic').reset_index()\n",
    "df_positive_sentences_by_topic_pt.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize each count by total number of (tagged) negative sentences per hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_count_by_hotel = df_negative_sentences.groupby('hotel_url').count().reset_index()[['hotel_url','review_topic']]\n",
    "df_negative_sentences_count_by_hotel.rename({'review_topic':'sentences_count'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_sentences_count_by_hotel = df_positive_sentences.groupby('hotel_url').count().reset_index()[['hotel_url','review_topic']]\n",
    "df_positive_sentences_count_by_hotel.rename({'review_topic':'sentences_count'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt = df_negative_sentences_by_topic_pt.merge(df_negative_sentences_count_by_hotel,on='hotel_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_sentences_by_topic_pt = df_positive_sentences_by_topic_pt.merge(df_positive_sentences_count_by_hotel,on='hotel_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining number of tagged negative sentences for normalization\n",
    "#df_negative_sentences_by_topic_pt['sentences_count']=df_negative_sentences_by_topic_pt['sentences_count']-df_negative_sentences_by_topic_pt[-1]\n",
    "#df_negative_sentences_by_topic_pt = df_negative_sentences_by_topic_pt[df_negative_sentences_by_topic_pt['sentences_count']!=0.0]\n",
    "\n",
    "#df_positive_sentences_by_topic_pt['sentences_count']=df_positive_sentences_by_topic_pt['sentences_count']-df_positive_sentences_by_topic_pt[-1]\n",
    "#df_positive_sentences_by_topic_pt = df_positive_sentences_by_topic_pt[df_positive_sentences_by_topic_pt['sentences_count']!=0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt[[str(n)+'_pc' for n in range(-1,n_topics)]] = df_negative_sentences_by_topic_pt[[n for n in range(-1,n_topics)]].div(df_negative_sentences_by_topic_pt.sentences_count, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_sentences_by_topic_pt[[str(n)+'_pc' for n in range(-1,n_topics)]] = df_positive_sentences_by_topic_pt[[n for n in range(-1,n_topics)]].div(df_positive_sentences_by_topic_pt.sentences_count, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt.to_csv('./datasets/df_negative_sentences_by_topic_pt.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_sentences_by_topic_pt.to_csv('./datasets/df_positive_sentences_by_topic_pt.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate topic clustering against manually-annotated entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_annotated = pd.read_csv('./datasets/df_negative_sentences_annotated.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(4,3)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(5,0)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(6,0)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(7,3)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(9,1)\n",
    "\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(8,4)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(10,5)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(11,6)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(12,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_annotated = df_negative_sentences_annotated[['review_date','review_sentence','review_topic_annotated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_topic_validation = df_negative_sentences.merge(df_negative_sentences_annotated,on=['review_date','review_sentence'])\n",
    "df_negative_sentences_topic_validation = df_negative_sentences_topic_validation[~pd.isnull(df_negative_sentences_topic_validation['review_topic_annotated'])]\n",
    "df_negative_sentences_topic_validation['review_topic_annotated'] = df_negative_sentences_topic_validation['review_topic_annotated'].apply(lambda x:int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.88      0.89       152\n",
      "           0       0.74      0.45      0.56        31\n",
      "           1       0.70      0.61      0.65        23\n",
      "           2       0.81      0.96      0.88        26\n",
      "           3       0.84      0.54      0.66        48\n",
      "           4       0.58      0.58      0.58        19\n",
      "           5       0.85      0.92      0.88        25\n",
      "           6       0.52      0.81      0.64        42\n",
      "           7       0.77      1.00      0.87        23\n",
      "\n",
      "    accuracy                           0.78       389\n",
      "   macro avg       0.75      0.75      0.73       389\n",
      "weighted avg       0.80      0.78      0.78       389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report on manually-annotated data\n",
    "print(classification_report(df_negative_sentences_topic_validation['review_topic_annotated'],df_negative_sentences_topic_validation['review_topic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LDA model\n",
    "lda_model = models.LdaMulticore(corpus=corpus_neg_data, num_topics=NUM_TOPICS, id2word=neg_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model:\n",
      "Topic #0: 0.112*\"room\" + 0.064*\"bathroom\" + 0.053*\"clean\" + 0.030*\"door\" + 0.025*\"need\" + 0.020*\"toilet\" + 0.016*\"shower\" + 0.015*\"dirti\" + 0.014*\"light\" + 0.014*\"broken\" + 0.010*\"updat\" + 0.009*\"sink\" + 0.008*\"mold\" + 0.007*\"floor\" + 0.007*\"open\"\n",
      "Topic #1: 0.045*\"room\" + 0.035*\"staff\" + 0.021*\"smoke\" + 0.019*\"coffe\" + 0.017*\"tv\" + 0.017*\"facil\" + 0.016*\"chang\" + 0.014*\"wait\" + 0.013*\"check\" + 0.012*\"time\" + 0.011*\"renov\" + 0.010*\"rude\" + 0.010*\"minut\" + 0.009*\"cigarett\" + 0.009*\"lobbi\"\n",
      "Topic #2: 0.069*\"room\" + 0.021*\"nice\" + 0.018*\"wifi\" + 0.013*\"staff\" + 0.012*\"experi\" + 0.011*\"expect\" + 0.010*\"pictur\" + 0.010*\"move\" + 0.009*\"refriger\" + 0.008*\"filthi\" + 0.008*\"luggag\" + 0.008*\"book\" + 0.007*\"issu\" + 0.006*\"3\" + 0.006*\"absolut\"\n",
      "Topic #3: 0.121*\"breakfast\" + 0.027*\"air\" + 0.024*\"room\" + 0.019*\"food\" + 0.016*\"poor\" + 0.016*\"condit\" + 0.014*\"includ\" + 0.012*\"coffe\" + 0.010*\"high\" + 0.009*\"expens\" + 0.008*\"noisi\" + 0.008*\"condition\" + 0.008*\"free\" + 0.007*\"aw\" + 0.007*\"limit\"\n",
      "Topic #4: 0.067*\"room\" + 0.042*\"water\" + 0.024*\"shower\" + 0.022*\"nois\" + 0.021*\"hot\" + 0.016*\"ac\" + 0.016*\"loud\" + 0.015*\"cold\" + 0.015*\"park\" + 0.014*\"heat\" + 0.013*\"window\" + 0.012*\"hear\" + 0.011*\"fridg\" + 0.011*\"build\" + 0.010*\"1\"\n",
      "Topic #5: 0.086*\"bed\" + 0.047*\"room\" + 0.023*\"elev\" + 0.020*\"towel\" + 0.018*\"peopl\" + 0.018*\"sheet\" + 0.014*\"2\" + 0.012*\"comfort\" + 0.012*\"uncomfort\" + 0.010*\"pillow\" + 0.010*\"two\" + 0.009*\"enough\" + 0.009*\"go\" + 0.009*\"dirti\" + 0.009*\"long\"\n",
      "Topic #6: 0.040*\"smell\" + 0.038*\"dirti\" + 0.028*\"room\" + 0.028*\"carpet\" + 0.023*\"locat\" + 0.021*\"floor\" + 0.019*\"look\" + 0.017*\"lot\" + 0.014*\"pool\" + 0.012*\"hallway\" + 0.011*\"stain\" + 0.011*\"properti\" + 0.011*\"towel\" + 0.011*\"wall\" + 0.009*\"felt\"\n",
      "Topic #7: 0.031*\"check\" + 0.031*\"desk\" + 0.027*\"front\" + 0.019*\"room\" + 0.017*\"u\" + 0.017*\"call\" + 0.017*\"charg\" + 0.014*\"staff\" + 0.013*\"book\" + 0.011*\"manag\" + 0.010*\"card\" + 0.010*\"arriv\" + 0.009*\"ask\" + 0.008*\"phone\" + 0.007*\"bookingcom\"\n"
     ]
    }
   ],
   "source": [
    "print(\"LDA Model:\")\n",
    " \n",
    "for idx in range(NUM_TOPICS):\n",
    "    # Print the first 10 most representative topics\n",
    "    print(\"Topic #%s:\" % idx, lda_model.print_topic(idx, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"The staff was very unfriendly\"\n",
    "#bow_trial = neg_dictionary.doc2bow(clean_text(text))\n",
    "corpus_neg_data_lda_output = lda_model[corpus_neg_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data_closest_topic = []\n",
    "for review_item in corpus_neg_data_lda_output:\n",
    "    review_item_sorted = sorted(review_item,key=lambda x:-x[1])\n",
    "    if review_item_sorted[0][1]>0.05:\n",
    "        neg_data_closest_topic.append(review_item_sorted[0][0])\n",
    "    else:\n",
    "        neg_data_closest_topic.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
