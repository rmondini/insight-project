{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim.downloader as api\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from gensim import models, corpora\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.matutils import cossim\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained word embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')\n",
    "#glove_model50 = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to clean text (removing stopwords, lemmatization, stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "# remove additional generic words\n",
    "STOPWORDS = STOPWORDS + ['also','anything','area','around','ask','back','bad','basic','better','bit','cant',\n",
    "                         'complaint','cost','could','day','didnt','disgusting','dont','even','ever','everything',\n",
    "                         'extra','feel','get','good','great','horrible','hotel','hour','leave','like','line',\n",
    "                         'little','look','money','much','need','never','new','night','nothing','ok','old','one',\n",
    "                         'option','overall','paid','pay','per','picture','place','price','quite','rate','really',\n",
    "                         'recommend','said','say','see','service','stay','stayed','sure','terrible','thing',\n",
    "                         'think','time','time','told','took','turn','u','use','want','wasnt','way','well','went',\n",
    "                         'work','worst','worth','would']\n",
    "\n",
    "# initialize lemmatizer and stemmer\n",
    "wn_lemmatizer = WordNetLemmatizer()\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    tokenized_text = word_tokenize(text.lower())\n",
    "    cleaned_text = [wn_lemmatizer.lemmatize(p_stemmer.stem(t)) for t in tokenized_text if t not in STOPWORDS]\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import negative sentences dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences = pd.read_csv('./datasets/df_negative_sentences.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove empty reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences = df_negative_sentences[~pd.isnull(df_negative_sentences['review_sentence'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify set of topics and topic keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_comfort_topic = 'Noise noisy loud slam voice music thin wall hear' + ' Smell smelly odor stink' + ' Ac heat hot cold thermostat air vent ventilation fan adjust heater temperature'\n",
    "staff_topic = 'Staff rude unfriendly friendly polite front desk manager maid reception valet clerk housekeep waiter waitress' + ' Check checkin checkout communication experience bag early late reservation booking'\n",
    "breakfast_topic = 'Breakfast food egg bacon sausage toast potato waffle fruit omelette omelet cheese milk pastry coffee tea juice silverware plasticware cup plastic included selection taste fresh'\n",
    "facilities_topic = 'Facility elevator lift stair wheelchair pool jacuzzi gym vending spa sauna renovation bar restaurant lounge pet property' + ' WiFi internet connection' + ' Park lot car valet street'\n",
    "location_topic = 'Location surrounding far traffic highway walk street road neighborhood sketchy attraction center city town downtown nearby near walk transport subway park view safe dangerous drive'\n",
    "bathroom_topic = 'Bathroom shower tub bathtub drain curtain pressure sink water toiletry toilet mirror shampoo conditioner towel soap ply paper hair face wash vent ventilation fan window'\n",
    "room_amenities_topic = 'Room carpet curtain shade drape light outlet plug window tv balcony couch remote wall fridge refrigerator safe machine coffee tea kettle amenity microwave card door'\n",
    "bed_quality_topic = 'Bed thin sheet linen blanket cover comforter pillow hard soft firm mattress bug bedbug king double queen twin frame sleep pullout couch bunk comfortable flat'\n",
    "\n",
    "topics= [room_comfort_topic,staff_topic,breakfast_topic,facilities_topic,location_topic,bathroom_topic,room_amenities_topic,bed_quality_topic]\n",
    "n_topics = len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old set of topic keywords\n",
    "\n",
    "# room_comfort_topic = 'Noise noisy loud quiet party slam scream yell voice music sound thin wall hear talk' + 'Smell smelly smoke odor cigarette stink' + 'Ac heat heaterac hot cold warm chilly thermostat cool air conditioning vent ventilation fan adjust heater temperature'\n",
    "# staff_topic = 'Staff rude unfriendly friendly polite impolite front desk manager maid reception valet clerk reception housekeep waiter waitress' + 'Check in out checkin checkout communication experience bag early late reservation booking'\n",
    "# breakfast_topic = 'Breakfast food egg bacon sausage toast waffle fruit omelette omelet cheese milk pastry coffee tea juice silverware plasticware cup plastic included selection taste fresh'\n",
    "# facilities_topic = 'Facility elevator work lift stair floor disability wheelchair pool jacuzzi gym vending machine spa towel sauna renovation bar restaurant lounge pet friendly dinner lunch pit property' + 'WiFi wi fi internet slow connection signal fast spotty' + 'Park lot car valet street driveway'\n",
    "# location_topic = 'Location surrounding far traffic highway walk street road neighborhood sketchy attraction center city town downtown nearby near walk transport subway park view safe dangerous drive'\n",
    "# bathroom_topic = 'Bathroom stain shower tub bathtub drain curtain pressure sink water toiletry toilet mirror shampoo conditioner towel soap ply paper hair hand face wash vent ventilation fan window'\n",
    "# room_amenities_topic = 'Room tiny small big large spacious stain carpet curtain shade drape light view outlet plug window tv balcony couch service remote wall fridge refrigerator safe machine coffee tea kettle amenity microwave card door'\n",
    "# bed_quality_topic = 'Bed stain sheet linen blanket cover comforter pillow hard soft mattress bug bedbug king double queen frame'\n",
    "\n",
    "# topics= [room_comfort_topic,staff_topic,breakfast_topic,facilities_topic,location_topic,bathroom_topic,room_amenities_topic,bed_quality_topic]\n",
    "# n_topics = len(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize sentences into words and clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_neg_data = []\n",
    "for text in df_negative_sentences['review_sentence']:\n",
    "    tokenized_neg_data.append(clean_text(text))\n",
    "    \n",
    "tokenized_topics = []    \n",
    "for text in topics:\n",
    "    tokenized_topics.append(clean_text(text))\n",
    "    \n",
    "tokenized_neg_data_and_topics = tokenized_neg_data + tokenized_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_dictionary = corpora.Dictionary(tokenized_neg_data_and_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BoW vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_neg_data = [neg_dictionary.doc2bow(text) for text in tokenized_neg_data]\n",
    "corpus_neg_topics = [neg_dictionary.doc2bow(text) for text in tokenized_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build similarity matrix of word embeddings from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "termsim_index = WordEmbeddingSimilarityIndex(fasttext_model300)\n",
    "similarity_matrix = SparseTermSimilarityMatrix(termsim_index,neg_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute (soft) cosine similarity between sentences and topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data_topics = []\n",
    "for review_item in corpus_neg_data:\n",
    "    review_item_topics = []\n",
    "    for topic in corpus_neg_topics:\n",
    "        # using BoW vectors (cosine similarity)\n",
    "        #review_item_topics.append(cossim(review_item,topic))\n",
    "        # using BoW + word embeddings (soft cosine similarity)\n",
    "        review_item_topics.append(similarity_matrix.inner_product(review_item,topic,normalized=True))\n",
    "    neg_data_topics.append(review_item_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract topic with highest (soft) cosine similarity\n",
    "- We set a minimum threshold (0.05) that needs to be reached in order to assign a topic\n",
    "- If above-threshold topics are within 0.002, we assign -1 (i.e. no main topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data_closest_topic = []\n",
    "cossim_threshold = 0.05\n",
    "\n",
    "for review_item_topic_list in neg_data_topics:\n",
    "    if max(review_item_topic_list)>cossim_threshold:\n",
    "        review_item_array = np.array(review_item_topic_list)\n",
    "        sorted_review_item_array = sorted(review_item_array,reverse=True)\n",
    "        num_topics=1\n",
    "        for item in sorted_review_item_array[1:]:\n",
    "            if abs(item-sorted_review_item_array[0])<0.002:\n",
    "                num_topics+=1\n",
    "        if num_topics==1:\n",
    "            neg_data_closest_topic.append(np.argmax(review_item_topic_list))\n",
    "        else:\n",
    "            neg_data_closest_topic.append(-1)\n",
    "            #num_topics*=(-1)\n",
    "            #closest_topics = sorted(list(review_item_array.argsort()[num_topics:][::-1])) \n",
    "            #neg_data_closest_topic.append(closest_topics)\n",
    "    else:\n",
    "        neg_data_closest_topic.append(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign extracted topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences['review_topic'] = neg_data_closest_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    54422\n",
       " 6    52701\n",
       " 5    25216\n",
       " 1    24565\n",
       " 7    18235\n",
       " 2    18063\n",
       " 3    17588\n",
       " 0    15167\n",
       " 4    12231\n",
       "Name: review_topic, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize distribution of topics across corpus\n",
    "df_negative_sentences['review_topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct pivot table of hotels (index), topics (columns), and topic counts (values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic = df_negative_sentences.groupby(['hotel_url','review_topic']).size().reset_index()\n",
    "df_negative_sentences_by_topic.rename({0:'review_topic_count'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt = df_negative_sentences_by_topic.pivot_table(values='review_topic_count',index='hotel_url',columns='review_topic').reset_index()\n",
    "df_negative_sentences_by_topic_pt.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize each count by total number of negative sentences per hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_count_by_hotel = df_negative_sentences.groupby('hotel_url').count().reset_index()[['hotel_url','review_topic']]\n",
    "df_negative_sentences_count_by_hotel.rename({'review_topic':'sentences_count'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt = df_negative_sentences_by_topic_pt.merge(df_negative_sentences_count_by_hotel,on='hotel_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining number of tagged negative sentences for normalization\n",
    "#df_negative_sentences_by_topic_pt['sentences_count']=df_negative_sentences_by_topic_pt['sentences_count']-df_negative_sentences_by_topic_pt[-1]\n",
    "#df_negative_sentences_by_topic_pt = df_negative_sentences_by_topic_pt[df_negative_sentences_by_topic_pt['sentences_count']!=0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create columns with normalized topic counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt[[str(n)+'_pc' for n in range(-1,n_topics)]] = df_negative_sentences_by_topic_pt[[n for n in range(-1,n_topics)]].div(df_negative_sentences_by_topic_pt.sentences_count, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write pivot table out to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt.to_csv('./datasets/df_negative_sentences_by_topic_pt_we.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate topic extraction against manually-annotated entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_annotated = pd.read_csv('./datasets/df_negative_sentences_annotated.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing notation from old numbering of topics to new numbering\n",
    "\n",
    "# part 1 of notation changing\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(4,3)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(5,0)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(6,0)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(7,3)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(9,1)\n",
    "\n",
    "# part 2 of notation changing\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(8,4)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(10,5)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(11,6)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(12,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only relevant columns\n",
    "df_negative_sentences_annotated = df_negative_sentences_annotated[['review_date','review_sentence','review_topic_annotated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging dataframes and keeping only entries with manually-annotated topic\n",
    "df_negative_sentences_topic_validation = df_negative_sentences.merge(df_negative_sentences_annotated,on=['review_date','review_sentence'])\n",
    "df_negative_sentences_topic_validation = df_negative_sentences_topic_validation[~pd.isnull(df_negative_sentences_topic_validation['review_topic_annotated'])]\n",
    "df_negative_sentences_topic_validation['review_topic_annotated'] = df_negative_sentences_topic_validation['review_topic_annotated'].apply(lambda x:int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.81      0.88       152\n",
      "           0       0.72      0.49      0.58        37\n",
      "           1       0.64      0.70      0.67        23\n",
      "           2       0.83      0.96      0.89        26\n",
      "           3       0.86      0.65      0.74        48\n",
      "           4       0.54      0.67      0.60        21\n",
      "           5       0.79      0.97      0.87        35\n",
      "           6       0.52      0.74      0.61        46\n",
      "           7       0.72      1.00      0.84        23\n",
      "\n",
      "    accuracy                           0.77       411\n",
      "   macro avg       0.73      0.78      0.74       411\n",
      "weighted avg       0.80      0.77      0.78       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report on manually-annotated data\n",
    "print(classification_report(df_negative_sentences_topic_validation['review_topic_annotated'],df_negative_sentences_topic_validation['review_topic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach: LDA topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of topics\n",
    "NUM_TOPICS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the LDA model (multicore)\n",
    "lda_model = models.LdaMulticore(corpus=corpus_neg_data, num_topics=NUM_TOPICS, id2word=neg_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model:\n",
      "Topic #0: 0.112*\"room\" + 0.064*\"bathroom\" + 0.053*\"clean\" + 0.030*\"door\" + 0.025*\"need\" + 0.020*\"toilet\" + 0.016*\"shower\" + 0.015*\"dirti\" + 0.014*\"light\" + 0.014*\"broken\" + 0.010*\"updat\" + 0.009*\"sink\" + 0.008*\"mold\" + 0.007*\"floor\" + 0.007*\"open\"\n",
      "Topic #1: 0.045*\"room\" + 0.035*\"staff\" + 0.021*\"smoke\" + 0.019*\"coffe\" + 0.017*\"tv\" + 0.017*\"facil\" + 0.016*\"chang\" + 0.014*\"wait\" + 0.013*\"check\" + 0.012*\"time\" + 0.011*\"renov\" + 0.010*\"rude\" + 0.010*\"minut\" + 0.009*\"cigarett\" + 0.009*\"lobbi\"\n",
      "Topic #2: 0.069*\"room\" + 0.021*\"nice\" + 0.018*\"wifi\" + 0.013*\"staff\" + 0.012*\"experi\" + 0.011*\"expect\" + 0.010*\"pictur\" + 0.010*\"move\" + 0.009*\"refriger\" + 0.008*\"filthi\" + 0.008*\"luggag\" + 0.008*\"book\" + 0.007*\"issu\" + 0.006*\"3\" + 0.006*\"absolut\"\n",
      "Topic #3: 0.121*\"breakfast\" + 0.027*\"air\" + 0.024*\"room\" + 0.019*\"food\" + 0.016*\"poor\" + 0.016*\"condit\" + 0.014*\"includ\" + 0.012*\"coffe\" + 0.010*\"high\" + 0.009*\"expens\" + 0.008*\"noisi\" + 0.008*\"condition\" + 0.008*\"free\" + 0.007*\"aw\" + 0.007*\"limit\"\n",
      "Topic #4: 0.067*\"room\" + 0.042*\"water\" + 0.024*\"shower\" + 0.022*\"nois\" + 0.021*\"hot\" + 0.016*\"ac\" + 0.016*\"loud\" + 0.015*\"cold\" + 0.015*\"park\" + 0.014*\"heat\" + 0.013*\"window\" + 0.012*\"hear\" + 0.011*\"fridg\" + 0.011*\"build\" + 0.010*\"1\"\n",
      "Topic #5: 0.086*\"bed\" + 0.047*\"room\" + 0.023*\"elev\" + 0.020*\"towel\" + 0.018*\"peopl\" + 0.018*\"sheet\" + 0.014*\"2\" + 0.012*\"comfort\" + 0.012*\"uncomfort\" + 0.010*\"pillow\" + 0.010*\"two\" + 0.009*\"enough\" + 0.009*\"go\" + 0.009*\"dirti\" + 0.009*\"long\"\n",
      "Topic #6: 0.040*\"smell\" + 0.038*\"dirti\" + 0.028*\"room\" + 0.028*\"carpet\" + 0.023*\"locat\" + 0.021*\"floor\" + 0.019*\"look\" + 0.017*\"lot\" + 0.014*\"pool\" + 0.012*\"hallway\" + 0.011*\"stain\" + 0.011*\"properti\" + 0.011*\"towel\" + 0.011*\"wall\" + 0.009*\"felt\"\n",
      "Topic #7: 0.031*\"check\" + 0.031*\"desk\" + 0.027*\"front\" + 0.019*\"room\" + 0.017*\"u\" + 0.017*\"call\" + 0.017*\"charg\" + 0.014*\"staff\" + 0.013*\"book\" + 0.011*\"manag\" + 0.010*\"card\" + 0.010*\"arriv\" + 0.009*\"ask\" + 0.008*\"phone\" + 0.007*\"bookingcom\"\n"
     ]
    }
   ],
   "source": [
    "# print most representative words from extracted topics\n",
    "for idx in range(NUM_TOPICS):\n",
    "    print(\"Topic #%s:\" % idx, lda_model.print_topic(idx, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_neg_data_lda_output = lda_model[corpus_neg_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data_closest_topic = []\n",
    "for review_item in corpus_neg_data_lda_output:\n",
    "    review_item_sorted = sorted(review_item,key=lambda x:-x[1])\n",
    "    if review_item_sorted[0][1]>cossim_threshold:\n",
    "        neg_data_closest_topic.append(review_item_sorted[0][0])\n",
    "    else:\n",
    "        neg_data_closest_topic.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
