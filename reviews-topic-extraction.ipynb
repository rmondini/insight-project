{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from gensim import models, corpora\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.matutils import cossim\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained word embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to clean text (removing stopwords, lemmatization, stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "# remove additional generic words\n",
    "STOPWORDS = STOPWORDS + ['also','anything','area','around','ask','back','bad','basic','better','bit','cant',\n",
    "                         'complaint','cost','could','day','didnt','disgusting','dont','even','ever','everything',\n",
    "                         'extra','feel','get','good','great','horrible','hotel','hour','leave','like','line',\n",
    "                         'little','look','money','much','need','never','new','night','nothing','ok','old','one',\n",
    "                         'option','overall','paid','pay','per','picture','place','price','quite','rate','really',\n",
    "                         'recommend','said','say','see','service','stay','stayed','sure','terrible','thing',\n",
    "                         'think','time','time','told','took','turn','u','use','want','wasnt','way','well','went',\n",
    "                         'work','worst','worth','would']\n",
    "\n",
    "# initialize lemmatizer and stemmer\n",
    "wn_lemmatizer = WordNetLemmatizer()\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    tokenized_text = word_tokenize(text.lower())\n",
    "    cleaned_text = [wn_lemmatizer.lemmatize(p_stemmer.stem(t)) for t in tokenized_text if t not in STOPWORDS]\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import negative sentences dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences = pd.read_csv('./datasets/df_negative_sentences.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove empty reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences = df_negative_sentences[~pd.isnull(df_negative_sentences['review_sentence'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify set of topics and topic keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_comfort_topic = 'Noise noisy loud slam voice music thin wall hear' + ' Smell smelly odor stink' + ' Ac heat hot cold thermostat air vent ventilation fan adjust heater temperature'\n",
    "staff_topic = 'Staff rude unfriendly friendly polite front desk manager maid reception valet clerk housekeep waiter waitress' + ' Check checkin checkout communication experience bag early late reservation booking'\n",
    "breakfast_topic = 'Breakfast food egg bacon sausage toast potato waffle fruit omelette omelet cheese milk pastry coffee tea juice silverware plasticware cup plastic included selection taste fresh'\n",
    "facilities_topic = 'Facility elevator lift stair wheelchair pool jacuzzi gym vending spa sauna renovation bar restaurant lounge pet property' + ' WiFi internet connection' + ' Park lot car valet street'\n",
    "location_topic = 'Location surrounding far traffic highway walk street road neighborhood sketchy attraction center city town downtown nearby near walk transport subway park view safe dangerous drive'\n",
    "bathroom_topic = 'Bathroom shower tub bathtub drain curtain pressure sink water toiletry toilet mirror shampoo conditioner towel soap ply paper hair face wash vent ventilation fan window'\n",
    "room_amenities_topic = 'Room carpet curtain shade drape light outlet plug window tv balcony couch remote wall fridge refrigerator safe machine coffee tea kettle amenity microwave card door'\n",
    "bed_quality_topic = 'Bed thin sheet linen blanket cover comforter pillow hard soft firm mattress bug bedbug king double queen twin frame sleep pullout couch bunk comfortable flat'\n",
    "\n",
    "topics= [room_comfort_topic,staff_topic,breakfast_topic,facilities_topic,location_topic,bathroom_topic,room_amenities_topic,bed_quality_topic]\n",
    "n_topics = len(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize sentences into words and clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_neg_data = []\n",
    "for text in df_negative_sentences['review_sentence']:\n",
    "    tokenized_neg_data.append(clean_text(text))\n",
    "    \n",
    "tokenized_topics = []    \n",
    "for text in topics:\n",
    "    tokenized_topics.append(clean_text(text))\n",
    "    \n",
    "tokenized_neg_data_and_topics = tokenized_neg_data + tokenized_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_dictionary = corpora.Dictionary(tokenized_neg_data_and_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BoW vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_neg_data = [neg_dictionary.doc2bow(text) for text in tokenized_neg_data]\n",
    "corpus_neg_topics = [neg_dictionary.doc2bow(text) for text in tokenized_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build similarity matrix of word embeddings from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "termsim_index = WordEmbeddingSimilarityIndex(fasttext_model300)\n",
    "similarity_matrix = SparseTermSimilarityMatrix(termsim_index,neg_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute (soft) cosine similarity between sentences and topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data_topics = []\n",
    "for review_item in corpus_neg_data:\n",
    "    review_item_topics = []\n",
    "    for topic in corpus_neg_topics:\n",
    "        # using BoW vectors (cosine similarity)\n",
    "        #review_item_topics.append(cossim(review_item,topic))\n",
    "        # using BoW + word embeddings (soft cosine similarity)\n",
    "        review_item_topics.append(similarity_matrix.inner_product(review_item,topic,normalized=True))\n",
    "    neg_data_topics.append(review_item_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract topic with highest (soft) cosine similarity\n",
    "- We set a minimum threshold (0.05) that needs to be reached in order to assign a topic\n",
    "- If above-threshold topics are within 0.002, we assign -1 (i.e. no main topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data_closest_topic = []\n",
    "cossim_threshold = 0.05\n",
    "\n",
    "for review_item_topic_list in neg_data_topics:\n",
    "    if max(review_item_topic_list)>cossim_threshold:\n",
    "        review_item_array = np.array(review_item_topic_list)\n",
    "        sorted_review_item_array = sorted(review_item_array,reverse=True)\n",
    "        num_topics=1\n",
    "        for item in sorted_review_item_array[1:]:\n",
    "            if abs(item-sorted_review_item_array[0])<0.002:\n",
    "                num_topics+=1\n",
    "        if num_topics==1:\n",
    "            neg_data_closest_topic.append(np.argmax(review_item_topic_list))\n",
    "        else:\n",
    "            neg_data_closest_topic.append(-1)\n",
    "            #num_topics*=(-1)\n",
    "            #closest_topics = sorted(list(review_item_array.argsort()[num_topics:][::-1])) \n",
    "            #neg_data_closest_topic.append(closest_topics)\n",
    "    else:\n",
    "        neg_data_closest_topic.append(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign extracted topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences['review_topic'] = neg_data_closest_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    54422\n",
       " 6    52701\n",
       " 5    25216\n",
       " 1    24565\n",
       " 7    18235\n",
       " 2    18063\n",
       " 3    17588\n",
       " 0    15167\n",
       " 4    12231\n",
       "Name: review_topic, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize distribution of topics across corpus\n",
    "df_negative_sentences['review_topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct pivot table of hotels (index), topics (columns), and topic counts (values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic = df_negative_sentences.groupby(['hotel_url','review_topic']).size().reset_index()\n",
    "df_negative_sentences_by_topic.rename({0:'review_topic_count'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt = df_negative_sentences_by_topic.pivot_table(values='review_topic_count',index='hotel_url',columns='review_topic').reset_index()\n",
    "df_negative_sentences_by_topic_pt.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize each count by total number of negative sentences per hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_count_by_hotel = df_negative_sentences.groupby('hotel_url').count().reset_index()[['hotel_url','review_topic']]\n",
    "df_negative_sentences_count_by_hotel.rename({'review_topic':'sentences_count'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt = df_negative_sentences_by_topic_pt.merge(df_negative_sentences_count_by_hotel,on='hotel_url')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create columns with normalized topic counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt[[str(n)+'_pc' for n in range(-1,n_topics)]] = df_negative_sentences_by_topic_pt[[n for n in range(-1,n_topics)]].div(df_negative_sentences_by_topic_pt.sentences_count, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write pivot table out to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_by_topic_pt.to_csv('./datasets/df_negative_sentences_by_topic_pt_we.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate topic extraction against manually-annotated entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_sentences_annotated = pd.read_csv('./datasets/df_negative_sentences_annotated.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing notation from old numbering of topics to new numbering\n",
    "\n",
    "# part 1 of notation changing\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(4,3)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(5,0)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(6,0)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(7,3)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(9,1)\n",
    "\n",
    "# part 2 of notation changing\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(8,4)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(10,5)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(11,6)\n",
    "df_negative_sentences_annotated['review_topic_annotated']=df_negative_sentences_annotated['review_topic_annotated'].replace(12,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only relevant columns\n",
    "df_negative_sentences_annotated = df_negative_sentences_annotated[['review_date','review_sentence','review_topic_annotated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging dataframes and keeping only entries with manually-annotated topic\n",
    "df_negative_sentences_topic_validation = df_negative_sentences.merge(df_negative_sentences_annotated,on=['review_date','review_sentence'])\n",
    "df_negative_sentences_topic_validation = df_negative_sentences_topic_validation[~pd.isnull(df_negative_sentences_topic_validation['review_topic_annotated'])]\n",
    "df_negative_sentences_topic_validation['review_topic_annotated'] = df_negative_sentences_topic_validation['review_topic_annotated'].apply(lambda x:int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.81      0.88       152\n",
      "           0       0.72      0.49      0.58        37\n",
      "           1       0.64      0.70      0.67        23\n",
      "           2       0.83      0.96      0.89        26\n",
      "           3       0.86      0.65      0.74        48\n",
      "           4       0.54      0.67      0.60        21\n",
      "           5       0.79      0.97      0.87        35\n",
      "           6       0.52      0.74      0.61        46\n",
      "           7       0.72      1.00      0.84        23\n",
      "\n",
      "    accuracy                           0.77       411\n",
      "   macro avg       0.73      0.78      0.74       411\n",
      "weighted avg       0.80      0.77      0.78       411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report on manually-annotated data\n",
    "print(classification_report(df_negative_sentences_topic_validation['review_topic_annotated'],df_negative_sentences_topic_validation['review_topic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create f1-score dataframe for slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_dict = {'topic': ['no main topic','bathroom','bed quality','breakfast','facilities',\n",
    "                           'location','room amenities','room comfort','staff'],\n",
    "                 'f1-score': [0.88,0.87,0.84,0.89,0.74,0.60,0.61,0.58,0.67]}\n",
    "f1_score_df = pd.DataFrame.from_dict(f1_score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create topic pie chart for slides  \n",
    "(commented out for readability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_counts = df_negative_sentences['review_topic'].value_counts().rename_axis('Topic').reset_index(name='Count')\n",
    "df_topic_counts.replace(-1,'no main topic',inplace=True)\n",
    "df_topic_counts.replace(0,'room comfort',inplace=True)\n",
    "df_topic_counts.replace(1,'staff',inplace=True)\n",
    "df_topic_counts.replace(2,'breakfast',inplace=True)\n",
    "df_topic_counts.replace(3,'facilities',inplace=True)\n",
    "df_topic_counts.replace(4,'location',inplace=True)\n",
    "df_topic_counts.replace(5,'bathroom',inplace=True)\n",
    "df_topic_counts.replace(6,'room amenities',inplace=True)\n",
    "df_topic_counts.replace(7,'bed quality',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9,9))\n",
    "# df_topic_counts['Count'].plot(kind='pie', labels=df_topic_counts['Topic'], autopct='%1.1f%%', pctdistance=0.85, labeldistance=1.05, startangle=90, shadow=False, legend = False, fontsize=14)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach: LDA topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of topics\n",
    "NUM_TOPICS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the LDA model (multicore)\n",
    "lda_model = models.LdaMulticore(corpus=corpus_neg_data, num_topics=NUM_TOPICS, id2word=neg_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: 0.060*\"staff\" + 0.020*\"wall\" + 0.017*\"rude\" + 0.016*\"help\" + 0.014*\"bed\"\n",
      "Topic #1: 0.151*\"room\" + 0.073*\"small\" + 0.043*\"bathroom\" + 0.014*\"dirti\" + 0.014*\"facil\"\n",
      "Topic #2: 0.055*\"bed\" + 0.050*\"shower\" + 0.031*\"water\" + 0.028*\"bathroom\" + 0.017*\"hot\"\n",
      "Topic #3: 0.082*\"room\" + 0.030*\"smell\" + 0.025*\"towel\" + 0.019*\"noisi\" + 0.019*\"window\"\n",
      "Topic #4: 0.048*\"room\" + 0.022*\"book\" + 0.015*\"pool\" + 0.012*\"bed\" + 0.011*\"cold\"\n",
      "Topic #5: 0.101*\"breakfast\" + 0.036*\"room\" + 0.033*\"coffe\" + 0.020*\"poor\" + 0.016*\"food\"\n",
      "Topic #6: 0.039*\"check\" + 0.031*\"door\" + 0.029*\"room\" + 0.026*\"desk\" + 0.023*\"front\"\n",
      "Topic #7: 0.069*\"clean\" + 0.064*\"room\" + 0.027*\"elev\" + 0.022*\"park\" + 0.021*\"dirti\"\n"
     ]
    }
   ],
   "source": [
    "# print most representative words from extracted topics\n",
    "for idx in range(NUM_TOPICS):\n",
    "    print(\"Topic #%s:\" % idx, lda_model.print_topic(idx, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus_neg_data_lda_output = lda_model[corpus_neg_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
